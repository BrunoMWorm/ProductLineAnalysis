\documentclass[11pt]{article}
\usepackage{geometry}                % See geometry.pdf to learn the layout options. There are lots.
\geometry{letterpaper}                   % ... or a4paper or a5paper or ... 
%\geometry{landscape}                % Activate for for rotated page geometry
%\usepackage[parfill]{parskip}    % Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{epstopdf}
\usepackage[T1]{fontenc}

\usepackage[utf8]{inputenc}

\usepackage{setspace}
\doublespacing

\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png}

\title{Software Product Line Analysis Techniques}
\author{Ramy Shahin \\ rshahin@cs.toronto.edu}
\date{\today}                                           % Activate to display a given date or no date

\begin{document}
\maketitle

%\begin{abstract}
%TODO
%\end{abstract}

\section{Introduction}
A Software Product Line (SPL) is a family of related software products built from a common set of artifacts (e.g., design/specification models, source code, test cases). An SPL is composed of a set of features. A feature is an externally visible property, aspect or quality of a software system. An instance (product) of an SPL is composed of a subset of the SPL features. Not all combinations of features are valid though. A Feature Model (FM) - also known as a Variability Model (VM) - is a specification of the valid combinations of SPL features. An FM can be expressed as a boolean formula over features, or graphically as a Feature Diagram (FD).

When building an SPL, software analysis tools are still needed to find bugs, generate test cases, collect metrics or track progress. A plethora of tools already exists, covering many different categories of analyses. However, these tools work on the artifacts of a single product. Because an SPL encompasses a superset of features existing in a single product, those tools are not capable of identifying which artifacts belong to which set of products. Consequently, those tools cannot be used as is on an SPL. A naive solution is to generate all possible products of an SPL and run tools on each one of them. This is generally intractable though, because the number of products grows exponentially with the number of SPL features.

This position paper covers some research work attempting to solve this problem. One paper compares brute force (product-based), variability-aware (family-based) and sampling techniques\cite{Apel:2013}. Another extends this work to more elaborate sampling techniques and more general categories of analysis\cite{Liebig:2013}. At the theoretical end of the spectrum, one paper provides an elaborate mathematical foundation for lifting abstract interpretation based analyses to SPLs\cite{Midtgaard:2015}. At the other end, some papers provide pragmatic implementations of source code syntax checkers\cite{Gazzillo:2012}, type checkers\cite{Kastner:2012}, data flow analyses\cite{Bodden:2013}, and model checkers\cite{Classen:2013}.

\section{Variability-Aware Abstract Interpretation}

\newcommand{\configSpace}{\mathbb{K}}
\newcommand{\featSpace}{\mathbb{F}}
\newcommand{\lang}{\mathcal{L}}

In \cite{Midtgaard:2015}, a systematic approach to lift abstract interpretation analyses from single programs to SPLs is presented. The paper provides a rigorous  formal treatment of abstract interpretation applied to a simple imperative language, with variability at the statement level. Formal proofs of the soundness of the lifting approach are also presented. 

Given a programming language $\lang$, starting with an abstract interpretation (collecting semantics, an abstract domain, a Galois connection connecting the two, and an analysis function), the paper presents the \emph{lift} combinator, which lifts each of those components to tuples of values, with each value corresponding to a product configuration in the configuration space $\configSpace$. If $\lang$ is extended with static conditionals (e.g., CPP \#if) into a variability-aware language  $\lang'$, and the semantics are respectively extended, the \emph{lift} combinator can take a product-level abstract interpretation analysis and generate a variability-aware analysis out of it. 

The formulation presented lifts single values to tuples of values, each tuple $|\configSpace|$ in length. $|\configSpace|$ is exponential in the number of features in the feature space $\featSpace$, so implementing lifted analyses this way would be intractable. Caching and memoization of intermediate values can save some computational cycles, but still the overall computational complexity of the lifted analysis will grow exponentially with the number of features. Two optimizations are proposed in the paper: \emph{value sharing} and \emph{variational abstraction}.

\emph{Value sharing} attempts to eliminate redundancy within a lifted tuple by simply mapping individual values to presence conditions, instead of enumerating the values belonging to each of the configurations. This way if all configurations share the same values except for one, the tuple would only have two values with a presence condition each. The shorter the tuple, the faster the analysis since it will need to process less intermediate values. Presence conditions can be efficiently encoded and checked for satisfiability as CNF/DNF formulas or BDDs.

\emph{Variational abstraction} pushes abstraction up to the configuration space. Instead of lifting the exact product-level analysis up to the SPL, the lifted analysis can be abstracted to an over-approximation. Pretty much like all abstraction techniques, this trades accuracy for performance. \emph{Variational abstraction} is implemented the same way as other abstraction stages, starting with an abstract domain and a Galois connection together with all the corresponding proofs. Abstraction can vary from minimal ($\alpha_\featSpace$ where no abstraction takes place) to maximal ($\alpha_\phi$ where the configuration space is collapsed into a single value). Since Galois connections compose (the composition of two Galois connections is a Galois connection), \emph{variational abstraction} fits naturally in the presented calculational abstract interpretation framework.

This lifting approach was evaluated on a single analysis (reaching definitions). Three Java SPLs (Graph PL (GPL), Prevayler and BerkeleyDB) were used. However, the evaluation numbers presented are not aggregated across the 3 codebases, but rather for only 4 source code methods (2 from GPL, 1 from Prevayler and 1 from BerkeleyDB). The configuration space of each of those methods varies between 8 and 106 configurations.

The performance (running time) of three SPL analysis techniques is measured: brute force (per product analysis), lifted analysis with sharing, and lifted analysis with maximum variational abstraction (abstracting configuration variability away). Comparing against brute force analysis, speedup due to lifting with maximum variational abstraction grows exponentially with respect with the number of configurations, and almost identical to the average analysis performance of a single configuration. The speedup due to lifting with sharing also grows exponentially, but at a slower rate. Generalizing from those performance numbers is risky though because of highly restricted sample space (a single analysis on only 4 source code methods).

\section{Featured Transition Systems}

Classen et al.\cite{Classen:2013} address the problem of model checking variability-aware systems. The paper introduces the Featured Transition System (FTS) formalism of models, the feature Linear Temporal Logic (fLTL) for expressing temporal logic properties, and the SNIP model checker that checks fLTL properties against FTS models.

An FTS extends a Labeled Transition System (LTS) with a total function $\gamma$ mapping state transitions to presence conditions. This way behavior due to different model variants can be guarded by the presence conditions of those variants. In addition, an FTS is non-monotonic in the sense that existing behavior can be removed by a variant by assigning the negation of the presence condition of that variant to the transitions associated with the behavior.

Parallel composition of FTSs is also defined similarly to that of LTSs. When two FTSs are composed in parallel, independent transition actions are asynchronously interleaved. However, shared actions are synchronized and their corresponding presence conditions are conjoined. 

Properties over FTSs are specified in fLTL, which associates presence conditions to LTL formulas. Now a variability-aware model checker needs to check an fLTL property against an FTS model. The checker returns true if the property holds in the set of products defined by the property's presence condition. If the property is violated in any of those products, a set of counterexample/presence condition pairs is returned. Each counterexample covers a set of products in which the property is violated, and each product in which the property is violated  has to be covered by a counterexample.

The FTS model checking algorithm extends the state reachability algorithm for LTSs with the identification of the sets of products in which each state is reachable from an initial state. Sets ot products are defined in terms of feature expressions, which are encoded as BDDs. The FD of the model is used to exclude invalid products. Since only a single counterexample is needed whenever a product violates the property, the search can be pruned for products where a counterexample has already been found.

The SNIP model checker implements FTS model checking. Its input language is fPromela, which extends Promela (used in the SPIN model checker) by feature expression guard annotation over statements. It also implements variability-aware vacuity detection and deadlock detection.

One shortcoming of this paper is that empirical evaluation is done on only one model (the mine pump controller model). This model is small compared to realistic models (only 457 FTS states), and the evaluation is done checking only 6 properties. With only one model (moreover, a small one), the evaluation results cannot be safely generalized. 

\section{Product Line Type Checking}

In \cite{Kastner:2012}, a Colored Featherweight Java (CFJ) type checker is formalized and certified using the Coq\cite{Bertot:2010} proof assistant. Featherweight Java (FJ) is a simplistic subset of Java, leaving out constructs such as assignment (mutation) and interfaces. CFJ adds IDE-assisted variability to FJ, where different source code features have different colors in the IDE. This type checker is further extended to fully cover Java constructs.

A product line is considered well-typed only if all the products that can be generated out of it are well-typed (typing is preserved by product generation). The type checker here takes the source code of a product line as input, and checks all variants for type errors. In addition to typing preservation, a second goal is backward compatibility. No new syntactic constructs were introduced, which allowed the use of existing tools.

One fundamental limitation of this work is that it severely restricts the allowed forms of variability. First, only disciplined annotations are supported. Although this does not restrict the expressivity of variability, it limits the applicability of this type checker to existing product lines that use undisciplined annotations. More importantly though, variability annotation is only supported within elements of syntactic sequences. For example, a sequence of methods (potentially empty) is defined. Each element (method) within that sequence can be annotated individually. However, variability is not supported for singleton syntactic constructs. This means that we cannot vary the subtype of a class or the return type of a method across products.

This restricted form of variability serves two purposes. First it fulfills the backward compatibility goal, because the 150\% representation (without the preprocessor macros) is still syntacticly correct. Moreover, it turns the variability type checking problem into reachability of definitions. For example, a method definition annotated by a presence condition has to be reachable by all the method calls across all product variants. 
 
The type checker has been evaluated on 5 Java product lines, ranging from 9 to 42 features. Some type errors were found by the checker in some product variants. The performance (in terms of time taken to type check the product line) was evaluated compared to approximate per-product performance, and on these 5 product lines processing time grew much slower than the number of variants. It is worth noting though that these product lines are relatively small, both in terms of number of lines of code and number of features. 

\section{Strategies for Product-line Verification}

In \cite{Apel:2013}, product-based, sample-based and family-based model-checking strategies of SPLs are compared. Product-based (generating all products and checking each one of them individually) is used as a baseline. Sample-based strategies only generate a sample of products (single-wise, pair-wise and triple-wise in terms of valid feature combinations). Finally, family-based checking checks the whole SPL in one shot, treating variability points as conditionals.

In this work the sampling strategies used are too primitive. Systems defects that are due to the interaction of more than 3 different features (which are not rare) will not be detected by the strategies presented in this paper, simply because this work only samples up to triple-wise feature combinations.

Their family-based approach is more interesting. Features are encoded as boolean variables, and feature expressions as Binary Decision Diagrams (BDDs). Variability within a source-code function is mapped into multiple implementations, with an additional dispatcher function choosing which implementation to call based on feature expressions. This simply reduces variability into conditionals, allowing existing model checkers to be used as is.

One caveat that is not explicitly mentioned in the paper is that this family-based approach is not applicable to annotative SPLs. The case studies presented are all generative (each feature is implemented separately and then composed into an SPL). Different function implementations together with the dispatcher function are generated as a part of the SPL generation. However, annotative SPLs are less strict when it comes to variability points (they don't all map to conditionals). Late Splitting and Early Joining can't be directly implemented in CPP-based SPLs for example.

The performance of the different strategies is compared in terms of their speedup with respect to the product-based baseline. In product-based and sample-based strategies, model checking is terminated once a defect is found in a product. However, in the family-based strategy it is not possible to terminate checking when a defect is found, simply because that defect does not necessarily exist in all products. This is a threat to validity of the performance numbers, not mentioned in the paper. The family-based strategy effectively tries to finds all defects in each product in the SPL, while product-based and strategy-based strategies only find the first defect (if exists). Comparing those two different metrics is thus misleading.

\section{Scalable Analysis of Variable Software}
In \cite{Liebig:2013}, variability-aware (family-based) static analyses are compared to some sample-based techniques. Two variability-aware C language analyses are implemented and evaluated: type checking and liveness analysis. Three relatively big open source systems were used for evaluation: the Linux kernel, the Busybox codebase, and the OpenSSL library.

In addition to focusing on static analysis as opposed to model checking, there are two main differences between this work and that of \cite{Apel:2013}. First, the variability-aware analyses are applied to annotative SPLs (using the CPP to incorporate variability). Because annotative SPLs and more permissive than generative SPLs in terms of syntactic variability, some building blocks had to be purposely designed to be variability-aware. Those include variability-aware Abstract Syntax Trees (ASTs), Control Flow Graphs (CFGs) and symbol tables. In addition, a dedicated variability-aware parser (incorporating CPP logic) is used.

The second difference with respect to \cite{Apel:2013} is that the sampling techniques used in the comparison are more elaborate. In addition to pair-wise sampling (covered in \cite{Apel:2013}), single configuration, random and coverage-based sampling were also evaluated.

Similar to \cite{Apel:2013}, the main principles guiding the design of the variability-aware analyses are late splitting and early joining. These principles maximize reuse of intermediate analysis information across different variants, eventually resulting in variability-aware analyses outperforming brute-force per-product analysis by orders of magnitude. A third principle implicit in \cite{Apel:2013} but explicitly spelled out here is local variability representation. This is the mechanism of maintaining variability within intermediate analysis values.

The evaluation presented in the paper justifies the hypotheses of the authors: the implemented variability-aware analyses under-perform single configuration analyses, but outperform the analysis of pair-wise samples. In addition, in some cases variability-aware analyses also outperform coverage-based analysis. More importantly, variability-aware analyses are complete in terms of covering all valid feature combinations (i.e. all valid products), while all the sampling techniques are incomplete in that regard.

\section{SPLLift}

In \cite{Bodden:2013}, inter-procedural data flow analysis (based on the IFDS \cite{Reps:1995} framework) is extended to annotative product lines. In IFDS, inter-procedural data flow analysis problems are encoded as graph reachability problems. The main idea behind lifting IFDS analyses is to guard data-flow properties of a program statements by presence conditions. This fits well within the IFDS framework because data flow properties are boolean expressions.

This lifting approach scales well with the number of features. Complexity grows polynomially with the number of statements in an SPL, rather than exponentially in the number of features. In addition, the implementation takes the feature model of the SPL into consideration, pruning statements with invalid presence conditions. This eliminates the need to do excessive computations that are of no value to the SPL analysis. Presence conditions are encoded as BDDs, which further optimizes their satisfiability checks.

This work was evaluated on 3 lifted analyses: Possible Types, Reaching Definitions and Uninitialized Variables. 4 real world SPLs were used as case studies: BerkeleyDB, GPL, Lampiro and MM08. Performance results show that the lifted analyses run in minutes (in some cases seconds), while brute force analysis would take years for some of the case studies. One thing to note though is that the correctness of the lifting approach is shown empirically rather than with a logical proof.

\section{SuperC}
In \cite{Gazzillo:2012}, a variability-aware C-language parser and preprocessor are presented and evaluated against a similar C parser implemented as a part of the TypeChef project \cite{Kastner:2011}. SuperC includes a lexer, a preprocessor and a Fork Merge LR (FMLR) parser. Several optimizations have been implemented to lower the number of forked sub-parsers, and consequently speedup parsing. On the x86 Linux kernel codebase, SuperC is 3.4 to 3.8 times faster than TypeChef.

The idea behind FMLR parsing is to fork sub-parsers (initially sharing the state of their parent) on each variability point. A naive implementation would result in a number of sub-parsers exponential in the number of variability features. To prevent this exponential explosion, SuperC implements 4 optimizations: follow-set calculation, early reduces, lazy shifts, and shared reduces. With those optimizations, for almost all the Linux kernel compilation units the number of sub-parsers is less than 20.

In addition to the optimizations, SuperC uses Binary Decision Diagrams (BDDs) to encode and test the satisfiability of presence conditions, while TypeChef uses a SAT-solver. Presence conditions are conjuncted on the nesting of static conditional compilation directives, and disjuncted on merges. With a few (tens) of propositional variables, conjunction and disjunction of BDDs is typically more efficient than applying the same operations to CNF-encoded boolean formulas (processed by SAT-solvers). As a result, BDDs also contribute to SuperC's speedup compared to TypeChef.

Another advantage of SuperC compared to TypeChef is that the SuperC preprocessor and parser take into account the possible interactions between different preprocessing and parsing rules of the C language. TypeChef misses some of those interactions (and also some non-standard preprocessing directives), which is the reason why it fails to parse thousands of the Linux kernel source files. SuperC on the other hand parses the whole codebase.

\bibliographystyle{abbrv}
\bibliography{quals} 
\end{document}  