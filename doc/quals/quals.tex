\documentclass[11pt]{article}
\usepackage{geometry}                % See geometry.pdf to learn the layout options. There are lots.
\geometry{letterpaper}                   % ... or a4paper or a5paper or ... 
%\geometry{landscape}                % Activate for for rotated page geometry
%\usepackage[parfill]{parskip}    % Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{epstopdf}
\usepackage[T1]{fontenc}

\usepackage[utf8]{inputenc}

\usepackage{setspace}
\doublespacing

\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png}

\title{Software Product Line Analysis Techniques}
\author{Ramy Shahin \\ rshahin@cs.toronto.edu}
\date{\today}                                           % Activate to display a given date or no date

\begin{document}
\maketitle

\begin{abstract}
TODO
\end{abstract}

\section{Introduction}
TODO

\section{Featured Transition Systems}
\cite{Classen:2013}

In \cite{Classen:2013}, Labeled Transition Systems (LTSs) are extended with feature expressions into Featured Transition Systems (FTSs). FTSs can be used to encode variability-aware models, which can be checked by the SNIP model checker. 

The paper provides a FTS-based formalism, together with model checking algorithms, complexity analysis (with proofs) and the featured LTL (fLTL) logic. Several state space reduction optimizations are also explained. The empirical evaluation highlights the speedup due to the optimized algorithm.

One shortcoming of this paper is that empirical evaluation is done on only one model (the mine pump controller model). This model is small compared to realistic models (only 457 FTS states), and the evaluation is done checking only 6 properties. With only one model (moreover, a small one), the evaluation results cannot be safely generalized. 
 
\section{SPLLift}

In \cite{Bodden:2013}, inter-procedural data flow analysis (based on the IFDS \cite{Reps:1995} framework) is extended to annotative product lines. In IFDS, inter-procedural data flow analysis problems are encoded as graph reachability problems. The main idea behind lifting IFDS analyses is to guard data-flow properties of a program statements by presence conditions. This fits well within the IFDS framework because data flow properties are boolean expressions.

This lifting approach scales well with the number of features. Complexity grows polynomially with the number of statements in an SPL, rather than exponentially in the number of features. In addition, the implementation takes the feature model of the SPL into consideration, pruning statements with invalid presence conditions. This eliminates the need to do excessive computations that are of no value to the SPL analysis.

This work was evaluated on 3 lifted analyses: Possible Types, Reaching Definitions and Unititialized Variables. 4 real world SPLs were used as case studies: BerkeleyDB, GPL, Lampiro and MM08. Performance results show that the lifted analyses run in minutes (in some cases seconds), while brute force analysis would take years for some of the case studies. One thing to note though is that the correctness of the lifting approach is shown empirically rather than with a logical proof.

\section{Product Line Type Checking}

In \cite{Kastner:2012}, a Colored Featherweight Java (CFJ) type checker is formalized and certified using the Coq\cite{Bertot:2010} proof assistant. Featherweight Java (FJ) is a simplistic subset of Java, leaving out constructs such as assignment (mutation) and interfaces. CFJ adds IDE-assisted variability to FJ, where different source code features have different colors in the IDE. This type checker is further extended to fully cover Java constructs.

A product line is considered well-typed only if all the products that can be generated out of it are well-typed (typing is preserved by product generation). The type checker here takes the source code of a product line as input, and checks all variants for type errors. In addition to typing preservation, a second goal is backward compatibility. No new syntactic constructs were introduced, which allowed the use of existing tools.

One fundamental limitation of this work is that it severely restricts the allowed forms of variability. First, only disciplined annotations are supported. Although this does not restrict the expressivity of variability, it limits the applicability of this type checker to existing product lines that use undisciplined annotations. More importantly though, variability annotation is only supported within elements of syntactic sequences. For example, a sequence of methods (potentially empty) is defined. Each element (method) within that sequence can be annotated individually. However, variability is not supported for singleton syntactic constructs. This means that we cannot vary the subtype of a class or the return type of a method across products.

This restricted form of variability serves two purposes. First it fulfills the backward compatibility goal, because the 150\% representation (without the preprocessor macros) is still syntacticly correct. Moreover, it turns the variability type checking problem into reachability of definitions. For example, a method definition annotated by a presence condition has to be reachable by all the method calls across all product variants. 
 
The type checker has been evaluated on 5 Java product lines, ranging from 9 to 42 features. Some type errors were found by the checker in some product variants. The performance (in terms of time taken to type check the product line) was evaluated compared to approximate per-product performance, and on these 5 product lines processing time grew much slower than the number of variants. It is worth noting though that these product lines are relatively small, both in terms of number of lines of code and number of features. 

\section{Variability-Aware Abstract Interpretation}
\cite{Midtgaard:2015}

\section{Strategies for Product-line Verification}

In \cite{Apel:2013}, product-based, sample-based and family-based model-checking strategies of SPLs are compared. Product-based (generating all products and checking each one of them individually) is used as a baseline. Sample-based strategies only generate a sample of products (single-wise, pair-wise and triple-wise in terms of valid feature combinations). Finally, family-based checking checks the whole SPL in one shot, treating variability points as conditionals.

In this work the sampling strategies used are too primitive. Systems defects that are due to the interaction of more than 3 different features (which are not rare) will not be detected by the strategies presented in this paper, simply because this work only samples up to triple-wise feature combinations.

Their family-based approach is more interesting. Features are encoded as boolean variables, and feature expressions as Binary Decision Digarams (BDDs). Variability within a source-code function is mapped into multiple implementations, with an additional dispatcher function choosing which implementation to call based on feature expressions. This simply reduces variability into conditionals, allowing existing model checkers to be used as is.

One caveat that is not explicitly mentioned in the paper is that this family-based approach is not applicable to annotative SPLs. The case studies presented are all generative (each feature is implemented separately and then composed into an SPL). Different function implementations together with the dispatcher function are generated as a part of the SPL generation. However, annotative SPLs are less strict when it comes to variability points (they don't all map to conditionals). Late Splitting and Early Joining can't be directly implemented in CPP-based SPLs for example.

The performance of the different strategies is compared in terms of their speedup with respect to the product-based baseline. In product-based and sample-based strategies, model checking is terminated once a defect is found in a product. However, in the family-based strategy it is not possible to terminate checking when a defect is found, simply because that defect does not necessarily exist in all products. This is a threat to validity of the performance numbers, not mentioned in the paper. The family-based strategy effectively tries to finds all defects in each product in the SPL, while product-based and strategy-based strategies only find the first defect (if exists). Comparing those two different metrics is thus misleading.

\section{Scalable Analysis of Variable Software}
In \cite{Liebig:2013}, variability-aware (family-based) static analyses are compared to some sample-based techniques. Two variability-aware C language analyses are implemented and evaluated: type checking and liveness analysis. Three relatively big open source systems were used for evaluation: the Linux kernel, the Busybox codebase, and the OpenSSL library.

In addition to focusing on static analysis as opposed to model checking, there are two main differences between this work and that of \cite{Apel:2013}. First, the variability-aware analyses are applied to annotative SPLs (using the CPP to incorporate variability). Because annotative SPLs and more permissive than generative SPLs in terms of syntactic variability, some building blocks had to be purposely designed to be variability-aware. Those include variability-aware Abstract Syntax Trees (ASTs), Control Flow Graphs (CFGs) and symbol tables. In addition, a dedicated variability-aware parser (incorporating CPP logic) is used.

The second difference with respect to \cite{Apel:2013} is that the sampling techniques used in the comparison are more elaborate. In addition to pair-wise sampling (covered in \cite{Apel:2013}), single configuration, random and coverage-based sampling were also evaluated.

Similar to \cite{Apel:2013}, the main principles guiding the design of the variability-aware analyses are late splitting and early joining. These principles maximize reuse of intermediate analysis information across different variants, eventually resulting in variability-aware analyses outperformaing brute-force per-product analysis by orders of magnitude. A third principle implicit in \cite{Apel:2013} but explicitly spelled out here is local variability representation. This is the mechanism of maintaining variability within intermediate analysis values.

The evaluation presented in the paper justifies the hypotheses of the authors: the implemented variability-aware analyses under-perform single configuration analyses, but outperform the analysis of pair-wise samples. In addition, in some cases variability-aware analyses also outperform coverage-based analysis. More importantly, variability-aware analyses are complete in terms of covering all valid feature combinations (i.e. all valid products), while all the sampling techniques are incomplete in that regard.

\section{SuperC}
In \cite{Gazzillo:2012}, a variability-aware C-language parser and preprocessor are presented and evaluated against a similar C parser implemented as a part of the TypeChef project \cite{Kastner:2011}. SuperC includes a lexer, a preprocessor and a Fork Merge LR (FMLR) parser. Several optimizations have been implemented to lower the number of forked subparsers, and consequently speedup parsing. On the x86 Linux kernel codebase, SuperC is 3.4 to 3.8 times faster than TypeChef.

The idea behind FMLR parsing is to fork subparsers (initially sharing the state of their parent) on each variability point. A naive implementation would result in a number of subparsers exponential in the number of variability features. To prevent this exponential explosion, SuperC implements 4 optimizations: follow-set calculation, early reduces, lazy shifts, and shared reduces. With those optimizations, for almost all the Linux kernel compilation units the number of subparsers is less than 20.

In addition to the optimizations, SuperC uses Binary Decision Diagrams (BDDs) to encode and test the satisfiability of presence conditions, while TypeChef uses a SAT-solver. Presence conditions are conjuncted on the nesting of static conditional compilation directives, and disjuncted on merges. With a few (tens) of propositional variables, conjunction and disjunction of BDDs is typically more efficient than applying the same operations to CNF-encoded boolean formulas (processed by SAT-solvers). As a result, BDDs also contribute to SuperC's speedup compared to TypeChef.

Another advantage of SuperC compared to TypeChef is that the SuperC preprocessor and parser take into account the possible interactions between different preprocessing and parsing rules of the C language. TypeChef misses some of those interactions (and also some non-standard preprocessing directives), which is the reason why it fails to parse thousands of the Linux kernel source files. SuperC on the other hand parses the whole codebase.

\bibliographystyle{abbrv}
\bibliography{quals} 
\end{document}  